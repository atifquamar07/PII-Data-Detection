{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde90796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4203096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d4f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'train.json'\n",
    "file_test = 'test.json'\n",
    "\n",
    "MAXLEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1823fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa26c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00bb825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353c4c4",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "**Step 1**: Convert `labels` column into ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943bfb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O',\n",
    "  'B-NAME_STUDENT',\n",
    "  'I-NAME_STUDENT',\n",
    "  'B-EMAIL',\n",
    "  'I-EMAIL',\n",
    "  'B-USERNAME',\n",
    "  'I-USERNAME',\n",
    "  'B-ID_NUM',\n",
    "  'I-ID_NUM',\n",
    "  'B-PHONE_NUM',\n",
    "  'I-PHONE_NUM',\n",
    "  'B-URL_PERSONAL',\n",
    "  'I-URL_PERSONAL',\n",
    "  'B-STREET_ADDRESS',\n",
    "  'I-STREET_ADDRESS'\n",
    "]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5141688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapped_labels(labels):\n",
    "    mapped_labels = pd.DataFrame({\n",
    "        'mapped_labels': labels\n",
    "    })['mapped_labels'].map(label2id).tolist()\n",
    "\n",
    "    return mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51c7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical column -- friendlier for classifiers\n",
    "df['labels_cat'] = df['labels'].apply(create_mapped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e96b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample because too many non-PII examples\n",
    "filter = df['labels'].apply(lambda arr: any([l != 'O' for l in arr]))\n",
    "downsampled_df = df[filter]\n",
    "\n",
    "train, valid = train_test_split(downsampled_df, test_size=0.1, shuffle=True, random_state=22124)\n",
    "\n",
    "def create_dataset(df):\n",
    "    ds = Dataset.from_dict({\n",
    "        'document': [d for d in df['document']],\n",
    "        'full_text': [ft for ft in df['full_text']],\n",
    "        'tokens': [t for t in df['tokens']],\n",
    "        'trailing_whitespace': [tw for tw in df['trailing_whitespace']],\n",
    "        'labels': [l for l in df['labels']],\n",
    "        'labels_cat': [ml for ml in df['labels_cat']]\n",
    "    })\n",
    "    return ds\n",
    "\n",
    "train_ds = create_dataset(train)\n",
    "valid_ds = create_dataset(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0df1d",
   "metadata": {},
   "source": [
    "#### Some preprocessing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        # pdb.set_trace()\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    After running tokenizer, word ids can get misaligned\n",
    "    need to re-align BIO labels, i.e. make sure split-up words\n",
    "    get tagged as I-, [CLS] and [SEP] etc. are given sentinel values\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], padding=True, truncation=True, is_split_into_words=True, max_length=MAXLEN\n",
    "    )\n",
    "    # pdb.set_trace()\n",
    "    all_labels = examples[\"labels_cat\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)                \n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720f32f",
   "metadata": {},
   "source": [
    "## DistilBert LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1399837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = 'microsoft/deberta-v3-small'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2b299e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'distilbert/distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7de2362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3f76faa3b2488d9af14602cdcdb54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df57df0989de4d1e8aab857e16a306c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_ds.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_valid = valid_ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b92bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e5929",
   "metadata": {},
   "source": [
    "##### Define eval metrics before starting finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d3df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dca9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c0ff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81de48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='steps',  # Change to 'steps'\n",
    "    save_strategy='steps',  # Change to 'steps'\n",
    "    eval_steps=500,  # Adjust based on your dataset size\n",
    "    save_steps=500,  # Adjust based on your dataset size\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e19d0116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8500' max='8500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8500/8500 06:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.020062</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.546763</td>\n",
       "      <td>0.625514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.697842</td>\n",
       "      <td>0.713235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>0.653543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.708487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.795620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.807407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.791367</td>\n",
       "      <td>0.817844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>0.843972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>0.866426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.825279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.848921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>0.798507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012685</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>0.865455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.837037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.841727</td>\n",
       "      <td>0.860294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.841727</td>\n",
       "      <td>0.863469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8500, training_loss=0.005804179456304102, metrics={'train_runtime': 396.2013, 'train_samples_per_second': 21.454, 'train_steps_per_second': 21.454, 'total_flos': 1110812391936000.0, 'train_loss': 0.005804179456304102, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3225ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('distilbert-finetuned-downsampled-512')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d14c7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef2a064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from your directory\n",
    "model_path = 'distilbert-finetuned-downsampled-512'  # Update with the correct path\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7404dd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8adeb069b294f9dae9a95e5c705ccf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_test_data(example):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        example[\"tokens\"], \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        is_split_into_words=True, \n",
    "        max_length=MAXLEN,\n",
    "        return_tensors=\"pt\"  # Ensure the output is PyTorch tensors\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize test data\n",
    "\n",
    "tokenized_test = Dataset.from_dict({\n",
    "    'document': df_test['document'],\n",
    "    'full_text': df_test['full_text'],\n",
    "    'tokens': df_test['tokens'],\n",
    "    'trailing_whitespace': df_test['trailing_whitespace']\n",
    "}).map(tokenize_test_data, batched=True)\n",
    "\n",
    "# Ensure tokenized_test is properly formatted\n",
    "assert isinstance(tokenized_test, Dataset), \"tokenized_test is not a Dataset object\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a25543b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcb83f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49f00edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to DataFrame\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b106785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the predictions\n",
    "predicted_df = pd.DataFrame(columns=['row_id', 'document', 'token', 'label'])\n",
    "row_id = 0\n",
    "\n",
    "# Iterate over each example in the test dataset\n",
    "for i, example_labels in enumerate(predicted_labels):\n",
    "    # Iterate over tokens in the example\n",
    "    for j, label_id in enumerate(example_labels):\n",
    "        # Only include positive PII label values (excluding O)\n",
    "        if label_list[label_id] != 'O':\n",
    "            predicted_df.loc[row_id] = [row_id, df_test['document'][i], j, label_list[label_id]]\n",
    "            row_id += 1\n",
    "\n",
    "# Save predictions to file\n",
    "predicted_df.to_csv('distil-bert-predicted_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c115eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
